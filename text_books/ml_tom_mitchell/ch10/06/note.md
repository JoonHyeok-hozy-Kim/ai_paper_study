* [Back to Machine Learning Tom Mitchell Main](../../main.md)

# 10.6 Induction as Inverted Deduction
- Ideation)
  - Induction is just the inverse of deduction!

- Notation) 
  - $X \vdash Y$
    - Meanings)
      - $Y$ follows deductively from $X$
      - $X$ entails $Y$

### Concept) Deductive Expression of Learning
- Def.)
  - Let
    - $`D = \{\langle x_i, f(x_i) \rangle : \exists i\}`$ : some data
      - where 
        - $x_i$ : the $i$-th training instance
        - $f(x_i)$ : the target value of $x_i$
    - $B$ : some partial background knowledge
    - $h$ : the target hypothesis we want to learn
  - Then
    - $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$
      - i.e.) Then **learning** is the problem of discovering a hypothesis $h$, such that the classification $f(x_i)$ of each training instance $x_i$ follows deductively from the hypothesis $h$, the description of $x_i$, and any other background knowledge $B$ known to the system.
#### e.g.) Child(u,v)
  - Settings)
    - Suppose we want to learn a target concept...
      - $Child(u,v)$ : pairs of people $\langle u, v \rangle$ such that the child of $u$ is $v$
    - A single positive example is given as follows.
      - $Child(Bob, Sharon)$
        - where the instances $Bob$ and $Sharon$ are described by the literals...
          - $Male(Bob)$
          - $Female(Sharon)$
          - $Father(Sharon, Bob)$
    - We have the general background knowledge
      - $Parent(u,v) \leftarrow Father(u,v)$
  - Then, we can denote the above situation in the following problem structure.
    - $`x_i : Male(Bob), Female(Sharon), Father(Sharon, Bob)`$
    - $`f(x_i) : Child(Bob, Sharon)`$
    - $`B : Parent(u,v) \leftarrow Father(u,v)`$
  - Among many possible hypotheses, following two satisfy the constraint $(B \wedge h \wedge x_i) \vdash f(x_i)$
    - $h_1 : Child(u,v)\leftarrow Father(v,u)$
    - $h_2 : Child(u,v)\leftarrow Parent(v,u)$
      - cf.) Refer to [Constructive Induction below](#concept-constructive-induction) for more description

<br>

### Concept) Constructive Induction
- Def.)
  - The process of augmenting the set of predicates, based on background knowledge
- E.g.)
  - Consider the case of learning $Child(u,v)$ [above](#eg-childuv).
    - $h_1 : Child(u,v)\leftarrow Father(v,u)$
      - cf.)
        - Entailed by $h_1\wedge x_i$.
        - $B$ not needed.
    - $h_2 : Child(u,v)\leftarrow Parent(v,u)$
      - cf.)
        - Entailed by $B\wedge h_2 \wedge x_i$.
        - Cannot be deducted solely from $h_2 \wedge x_i$.
        - This is how the background knowledge expands the set of acceptable hypotheses for a given set of training data.
          - i.e.) The Constructive Induction!

<br>

### Concept) Inverse Entailment Operator
- Def.)
  - $`O(B,D)=h \textrm{ such that }(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$
    - Desc.)
      - An inverse entailment operator, $O(B,D)$ takes the training data $`D = \{\langle x_i, f(x_i) \rangle : \exists i\}`$ and the background knowledge $B$ as input and produces as output a hypothesis $h$ satisfying the equation $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$.
- e.g.)
  - the Minimum Description Length principle in ILP
- Props.)
  - The equation $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$ **subsumes our previous** concept of learning
    - Finding some general concept $h$ that matches a given set of training examples $D$.
  - By incorporating the notion of background information $B$, this formulation allows a more rich definition of when a hypothesis may be said to "fit" the data.
    -  as long as $f(x_i)$ follows deductively from $(B\wedge h \wedge x_i)$.
  - By incorporating background information $B$, this formulation invites learning methods that use this background information to guide the search for $h$, rather than merely searching the space of syntactically legal hypotheses.
- Difficulties)
  - $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$ does not naturally accommodate noisy training data.
    - Desc.)
      - There may be errors in the observed $\langle x_i, f(x_i) \rangle$.
      - Such errors can produce an inconsistent set of constraints on $h$.
      - Unfortunately, most formal logic frameworks cannot distinguish between truth and falsehood once they are given inconsistent sets of assertions.
  - The hypothesis space generated by $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$ is too large to search all the suggested hypotheses.
    - Desc.)
      - Recall that [the first-order logic](../02/note.md#concept-first-order-rule) was so expressive.
      - Also, thanks to the help of $B$, the number of hypotheses that satisfy $`(\forall \langle x_i, f(x_i) \rangle \in D) (B \wedge h \wedge x_i) \vdash f(x_i)`$ is also massive.
  - Despite our intuition that background knowledge $B$ should help constrain the search for a hypothesis, in most ILP systems the complexity of **the hypothesis space search increases as background knowledge B is increased**.



<br>

* [Back to Machine Learning Tom Mitchell Main](../../main.md)