[Back to AI Main](../../README.md)

<br>

# Elements of Information Theory (2006)
*THOMAS M. COVER, JOY A. THOMAS*


## 2. Entropy, Relative Entropy, and Mutual Information
|No.|Chapter|Keywords|
|:-:|:------|:-------|
|2.1|[Entropy](ch02/01/note.md)|- |
|2.2|[Joint Entropy and Conditional Entropy](ch02/02/note.md)|- Chain Rule|
|2.3|[Relative Entropy and Mutual Information](ch02/03/note.md)|- Relative Entropy (Kullbackâ€“Leibler Distance) <br> - Mutual Information|
|2.4|[Relationship between Entropy and Mutual Information](ch02/04/note.md)|- Self Information|
|2.5|[Chain Rules for Entropy, Relative Entropy, and Mutual Information](ch02/05/note.md)|- Chain Rule for Entropy <br>- Conditional Mutual Information <br> - Chain Rule for Information <br> - Chain Rule for Relative Entropy|





<br><br>

[Back to AI Main](../../README.md)