[Back to Linear Algebra main](../../main.md)

# 20. Cramer's Rule, Inverse Matrix, and Volume / 21. Eigenvalues and Eigenvectors
### Concept) Inverse Matrix
- Def.)
  - $`A^{-1}`$ of $`A`$ s.t. $`AA^{-1} = I`$
- Prop.)
  - $`\displaystyle A^{-1} = \frac{1}{\det{A}} C^\top`$  where $`C = [c_{ij}]`$ s.t. $`c_{ij}`$ is the [cofactor](1819.md#concept-cofactors) of $`a_{ij}`$

<br>

### Concept) Craimer's Rule
- Thm.)
  - For $`Ax = b`$ where
    - $`A = \begin{bmatrix} a_1 & a_2 & \cdots & a_n \end{bmatrix}\in\mathbb{R}^{n\times n}`$
    - $`x = \begin{bmatrix} x_1\\x_2\\\vdots\\x_n \end{bmatrix},b\in\mathbb{R}^n`$ s.t. 
  - $`\displaystyle x_i = \frac{\det{A}}{\det{B_i}}`$ 
    - where $`B_i`$ is $`A`$ with column $`i`$ replaced by $`b`$
      - i.e.) $`B_i = \begin{bmatrix} a_1 & \cdots & a_{i-1} & b & a_{i+1} & \cdots & a_n \end{bmatrix}\in\mathbb{R}^{n\times n}`$

<br>

### Concept) Eigenvalue and Eigenvector
- Def.)
  - $`x\in\mathbb{R}^n`$ is the eigenvector of $`A\in\mathbb{R}^{n\times n}`$ iff.
    - $`Ax`$ is parallel to $`x`$.
      - i.e.) $`Ax = \lambda x, \quad \exists\lambda\in\mathbb{R}`$
  - $`\lambda`$ is the eigenvalue of $`A`$.
- Props.)
  - If $`A`$ is singular, $`\lambda = 0`$ is an eigenvalue.
    - Pf.)
      - Since $`A`$ is singular, $`\exists x'\in\mathbb{R}^n`$ s.t. $`x'\ne 0 \wedge Ax = 0`$.
      - Thus, $`Ax = 0 = \lambda x'`$.
      - $`\therefore \exists\lambda = 0`$
  - Any [projection matrix](1415.md#concept-projection-matrix-on-r2) $`P`$ has the eigenvalue of 1 and 0.
    - Pf.)
      - Suppose we have a hyperplane $`A\in\mathbb{R}^{n\times n}`$ and a vector $`b\in\mathbb{R}^n`$.
        - Then we have a projection matrix $`P\in\mathbb{R}^{n\times n}`$ s.t. $`\text{proj}_A(b) = Pb`$
        - Now put $`x = \text{proj}_A(b)\in\mathbb{R}^n`$.
        - Then $`Px = x`$.
        - Thus, $`\lambda = 1`$ is an eigenvalue of $`P`$.
      - Also, consider a vector $`c\in\mathbb{R}^n`$ s.t. $`c\perp A \wedge c\ne 0`$.
        - Then, $`\text{proj}_A(c) = Pc = 0`$
        - Thus, $`Pc = 0\cdot c`$.
        - Hence, $`\lambda = 0`$ is an eigenvalue of $`P`$. 
  - $`\displaystyle\sum_i \lambda_i = \sum_i \text{diag}(A)_i = \text{trace}(A)`$
  - $`\displaystyle\prod_i \lambda_i = \det A`$
  - $`(A+nI)x = (\lambda + n)x, \forall n\in\mathbb{R}`$
  - For a triangular matrix, 
    - $`\lambda = \text{diag}(A)`$

<br>

### Tech.) How to get Eigenvalue and Eigenvector
- Idea)
  - Recall $`Ax = \lambda x`$.
  - Thus, $`(A-\lambda I)x = 0`$
    - i.e.) $`(A-\lambda I)`$ must be singular.
  - Hence, $`\det(A-\lambda I) = 0`$.
- Procedure)
  - Get $`\lambda`$s with $`\det(A-\lambda I) = 0`$.
  - Get $`x_i`$ for each $`\lambda_i`$ 



<br>

[Back to Linear Algebra main](../../main.md)