[Back to Linear Algebra main](../../main.md)

# 29. Singular Value Decomposition
### Concept) Singular Value Decomposition (SVD)
- Def.)
  - $`A = U\Sigma V^\top`$
    - where
      - $`U, V`$ are orthogonal
      - $`\Sigma`$ is diagonal
  - Special Case)
    - [Symmetric Positive Definite](2526.md#concept-symmetric-matrix) : $`A = Q\Lambda Q^\top`$
- Derivation)
  - Let $`A\in\mathbb{R}^{m\times n}`$.
  - For $`r = \text{rank}(A)`$
    - $`v_1, \cdots, v_r \in\text{row}(A)\subseteq\mathbb{R}^{n}`$ s.t. $`v_i \perp v_j, \forall i\ne j`$
      - i.e.) the basis of the row space
    - $`u_1, \cdots, u_r \in\text{column}(A)\subseteq\mathbb{R}^{m}`$ s.t. $`u_i \perp u_j, \forall i\ne j`$
      - i.e.) the basis of the column space
    - $`\exists \sigma_i`$ s.t. $`\sigma_i u_i = Av_i, \; (i=1,\cdots,r)`$ : the singular values.
  - Then, the above relation can be written in the matrix form as   
    $`\underbrace{\begin{bmatrix} u_1 & u_2 & \cdots & u_r \end{bmatrix}}_{\mathbb{R}^{m\times r}} \underbrace{\begin{bmatrix} \sigma_1 & 0 & \cdots & 0 \\ 0 & \sigma_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \sigma_r \end{bmatrix}}_{\mathbb{R}^{r\times r}} = A \underbrace{\begin{bmatrix} v_1 & v_2 & \cdots & v_r \end{bmatrix}}_{\mathbb{R}^{n\times r}}`$
  - However, we should also consider $`i = r+1, r+2, \cdots, n`$
    - Cases)
      - Square Matrix and Full Rank : $`m=n=\text{rank}(A) = r`$  
          $`\begin{aligned}
              A 
              &= \begin{bmatrix} u_1 & u_2 & \cdots & u_n \end{bmatrix}\begin{bmatrix} \sigma_1 & 0 & \cdots & 0 \\ 0 & \sigma_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \sigma_n \end{bmatrix} \begin{bmatrix} v_1 & v_2 & \cdots & v_n \end{bmatrix}^{-1} \\
              &= U\Sigma V^{-1} \\
              &= U\Sigma V^\top \quad (\because \text{By definition } v_i \text{ is orthonormal}) \\
          \end{aligned}`$
      - Not Full Rank : $`m,n \gt \text{rank}(A) = r`$  
        - Then 
          - Singular values : $`\sigma_i = \begin{cases} \text{eigenvalues of } A^\top A & (i=1,\cdots,r) \\ 0 & (i = r+1, \cdots, n) \end{cases}`$
          - $`(m-r)`$ vectors that are orthogonal to $`\text{column}(A)\subseteq\mathbb{R}^m`$
            - i.e.) $`u_{r+1}, \cdots, u_m \in\text{Null}(A^\top)`$
          - $`(n-r)`$ vectors that are orthogonal to $`\text{row}(A)\subseteq\mathbb{R}^n`$
            - i.e.) $`v_{r+1}, \cdots, v_n \in\text{Null}(A)`$
        - Thus,   
          $`\begin{aligned}
              A 
              &= \begin{bmatrix} \underbrace{\begin{matrix}u_1 & \cdots & u_r\end{matrix}}_{\text{basis of col}(A)} & \underbrace{\begin{matrix}u_{r+1} & \cdots & u_m\end{matrix}}_{\text{basis of Null}(A^\top)} \end{bmatrix}\begin{bmatrix} \sigma_1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ 0 & \sigma_2 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \sigma_r & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \end{bmatrix} \begin{bmatrix} \underbrace{\begin{matrix}v_1 & \cdots & v_r\end{matrix}}_{\text{basis of row}(A)} & \underbrace{\begin{matrix}v_{r+1} & \cdots & v_n\end{matrix}}_{\text{basis of Null}(A)} \end{bmatrix}^{\top} \\
              &= U\Sigma V^\top \quad \text{where } \begin{cases} U\in\mathbb{R}^{m\times m} \\\Sigma\in\mathbb{R}^{m\times n} \\ V\in\mathbb{R}^{n\times n} \\\end{cases} \\
              &= U\Sigma V^\top \quad (\because \text{By definition } v_i \text{ is orthonormal}) \\
          \end{aligned}`$
  - Then, we have   
    $`\begin{aligned}
        A^\top A &= (U\Sigma V^\top)^\top U\Sigma V^\top = V\Sigma U^\top U\Sigma V^\top \\
        &= V\Sigma^2 V^\top \quad (\because U^\top U = I_m)
    \end{aligned}`$
    - Here, $`V`$ is the matrix of eigenvectors and $`\sigma_i^2`$ are the eigenvalues of $`A^\top A`$.
    - Furthermore, $`\sigma_i^2 \gt 0, \forall i`$, so $`A^\top A`$ is positive definite.
- How to calculate)
  - Calculate $`A^\top A`$.
  - Get the eigenvalues and eigenvectors of $`A^\top A`$.
  - Then, the eigenvalues form $`\Sigma^2`$ and the corresponding eigenvectors form $`V`$.
    - We may choose $`V`$ that is normalized!
  - Calculate $`U`$ from $`Av_i = \sigma_i u_i \Rightarrow VA = \Sigma U`$
  - Finally, we have $`A = U\Sigma V^\top`$
- e.g.)
  - Consider $`A = \begin{bmatrix} 4&4\\-3&3 \end{bmatrix}`$.
  - Then, $`A^\top A = \begin{bmatrix} 4&-3\\4&3 \end{bmatrix}\begin{bmatrix} 4&4\\-3&3 \end{bmatrix} = \begin{bmatrix} 25&7 \\ 7&25 \end{bmatrix}`$
  - Also, we may get
    - $`\begin{bmatrix} 4&4\\-3&3 \end{bmatrix}\begin{bmatrix} 1/\sqrt{2}\\1/\sqrt{2} \end{bmatrix} = 32\begin{bmatrix} 1/\sqrt{2}\\1/\sqrt{2} \end{bmatrix}`$
    - $`\begin{bmatrix} 4&4\\-3&3 \end{bmatrix}\begin{bmatrix} 1/\sqrt{2}\\-1/\sqrt{2} \end{bmatrix} = 18\begin{bmatrix} 1/\sqrt{2}\\-1/\sqrt{2} \end{bmatrix}`$
  - Thus, $`V = \begin{bmatrix} 1/\sqrt{2}&1/\sqrt{2}\\1/\sqrt{2}&-1/\sqrt{2} \end{bmatrix}, \Sigma^2 = \begin{bmatrix} 32 & 0 \\ 0 & 18 \end{bmatrix}`$
  - Hence, $`\Sigma = \begin{bmatrix} 4\sqrt{2} & 0 \\ 0 & 3\sqrt{2} \end{bmatrix}`$
  - Also, $`AA^\top = \begin{bmatrix} 4&4\\-3&3 \end{bmatrix}\begin{bmatrix} 4&-3\\4&3 \end{bmatrix}=\begin{bmatrix} 32 & 0 \\ 0 & 18 \end{bmatrix}`$
  - Thus, $`AA^\top = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}\begin{bmatrix} 32 & 0 \\ 0 & 18 \end{bmatrix}\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}`$ and $`U = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}`$   
  $`\begin{aligned}
    \therefore A &= U\Sigma V^\top \\
    &= \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 4\sqrt{2} & 0 \\ 0 & 3\sqrt{2} \end{bmatrix} \begin{bmatrix} 1/\sqrt{2}&1/\sqrt{2}\\1/\sqrt{2}&-1/\sqrt{2} \end{bmatrix} \\
    &= \begin{bmatrix} 4&4 \\ 3 & -3 \end{bmatrix} \\
  \end{aligned}`$
- Interpretation)
  - Finding four bases of a matrix.
    - $`v_1, \cdots, v_r`$ : the orthonormal bases of $`\text{row}(A)`$
    - $`u_1, \cdots, u_r`$ : the orthonormal bases of $`\text{column}(A)`$
    - $`v_{r+1}, \cdots, v_n`$ : the orthonormal bases of $`\text{Null}(A)`$
    - $`u_{r+1}, \cdots, u_n`$ : the orthonormal bases of $`\text{Null}(A^\top)`$




<br>

[Back to Linear Algebra main](../../main.md)