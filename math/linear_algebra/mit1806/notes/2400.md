[Back to Linear Algebra main](../../main.md)

# 24. Markov Matrices; Fourier Series
### Concept) Markov Matrix
- Def.)
  - A square matrix $`A\in\mathbb{R}^{n\times n}`$ s.t.
    - [1] $`A_{ij}\ge 0, \quad \forall i,j`$
    - [2] All columns add to one.
      - This guarantees that $`\exists \lambda_i = 1`$
      - Then, it's power will be in the steady state.
  - e.g.)
    - $`A = \begin{bmatrix}
      0.1 & 0.01 & 0.3 \\
      0.2 & 0.99 & 0.3 \\
      0.7 & 0 & 0.4 \\
    \end{bmatrix}`$
- Key Properties)
  - $`\exists \lambda_i = 1`$
    - Prop.)
      - It's corresponding eigenvector $`x_i`$'s elements are all greater than or equal to 0.
        - i.e.) $`x_i \ge 0`$
    - Pf.)
      - Suppose $`\exists \lambda_i = 1`$.
      - Put $`B = A-\lambda_i I = A-I`$.
      - Then, all columns of $`B`$ adds to zero.
      - Now consider the system of equation $`B^\top x = 0`$.
        - cf.) All rows of $`B^\top`$ adds to zero.
      - Putting $`b_i`$ the column vectors of $`B^\top`$ (row vectors of $`B`$), we have
        - $`b_1x_1 + b_2x_2 + \cdots + b_nx_n = 0`$
      - Then $`x=\begin{bmatrix}
        1\\1\\\vdots\\1
      \end{bmatrix}\in\text{Null}(B^\top)`$
      - Thus, $`B^\top`$ is singular.
      - Hence, $`B`$ is singular.
  - $`\vert\lambda_j\vert \lt 1, \quad \forall j \ne i`$
- Derivation)
  - Recall from the [Differential Equation](2223.md#concept-system-of-differential-equations) that   
    $`\begin{aligned}
      u_k &= A^k u_0 \\
      &= \sum_{i=1}^n c_i \lambda_i^k x_i \quad \exists c_i \in\mathbb{R} \text{ and } \lambda_i, x_i \text{ are eigenvalue and eigenvector}
    \end{aligned}`$
- Application)
  - Consider the case that
    - $`u_{k+1} = Au_k`$ where $`A\in\mathbb{R}^{n\times n}`$ is a Markov matrix.
  - We want to get a steady state of this system.
    - i.e.) $`\displaystyle\lim_{k\rightarrow\infty}u_k`$
  - We know that
    - $`\displaystyle u_k = \sum_{i=1}^n c_i \lambda_i^k x_i`$
    - $`\lambda_1 = 1`$ and $`\vert \lambda_i \vert \lt 1`$
    - With the value of $`u_0`$, we can get $`c_1^*, \cdots, c_n^*`$.
    - Then $`\displaystyle\lim_{k\rightarrow\infty}u_k = c_1^* x_1`$
      - Why?)
        - $`\displaystyle\lim_{k\rightarrow\infty}\lambda_i = 0, \quad \forall i\ne 1`$

<br>

### Concept) Projections with Orthonormal Basis
- Settings)
  - $`q_1, \cdots, q_n`$ : orthonormal bases
- Props.)
  - $`\forall v\in\mathbb{R}^n, \exist c_i\in\mathbb{R}`$ s.t. $`\displaystyle\sum_{i=1}^n c_iq_i`$
    - cf.) Each coefficients can be easily denoted as $`c_i = q_i^\top v`$

<br>

### Concept) Fourier Series
- Def.)
  - $`f(x) = a_0 + a_1\cos{x} + b_1\sin{x} + a_2\cos{2x} + b_2\sin{2x} + a_3\cos{3x} + b_3\sin{3x} + \cdots`$
- Prop.)
  - The orthogonality of functions
    - Recall that the orthogonality of two vectors is defined by
      - $`\displaystyle v^\top w = \sum_{i=1}^n v_i w_i = 0`$
    - Likewise we can denote the orthogonality of two functions $`f,g`$ can be defined by
      - $`\displaystyle f^\top g = \int f(x)g(x)dx`$
  - Now going back to the Fourier Series...
    - $`\cos{x}`$ and $`\sin{x}`$ are periodic : $`[0, 2\pi]`$
    - Then $`\displaystyle \int_{0}^{2\pi} \sin(x)\cos(x)dx = 0`$
  - Going back to $`f(X)`$, we may get   
    $`\begin{aligned}
        \int_{0}^{2\pi} f(x)\cos(x) dx &= \int_{0}^{2\pi} (a_0 + a_1\cos{x} + b_1\sin{x} + a_2\cos{2x} + b_2\sin{2x} + \cdots)\cos(x) dx \\
        &= \int_{0}^{2\pi} a_1 \cos^2(x) dx \\
        &= a_1 \int_{0}^{2\pi} \cos^2(x) dx \\
        &= \pi a_1
    \end{aligned}`$

<br>

[Back to Linear Algebra main](../../main.md)