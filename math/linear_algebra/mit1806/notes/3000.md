[Back to Linear Algebra main](../../main.md)

# 30. Linear Transformations and Their Matrices
### Concept) Linear Transformation
- Def.)
  - $`T : \mathbb{R}^m \rightarrow \mathbb{R}^n`$ s.t.
    - $`u\in\mathbb{R}^n, v \in\mathbb{R}^m`$ s.t. $`u = T(v)`$
    - $`T(v_1+v_2) = T(v_1) + T(v_2), \;\forall v_1,v_2 \in\mathbb{R}^m`$
    - $`T(cv) = cT(v), \;\forall v \in\mathbb{R}^m, c\in\mathbb{R}`$
- e.g.)
  - [Projection](1415.md#concept-projection-matrix-on-r2)
  - Rotation
  - Matrix Multiplication : $`T(v) = Av, \; \exist A\in\mathbb{R}^{n\times m}`$
  - Derivative
- cf.) Non-examples
  - Shifting the plane
    - Must pass though the origin.

<br>

#### Tech.) How to construct a matrix that represents a linear transformation
- Idea)
  - For $`v\in\mathbb{R}`$ and $`v_1, \cdots, v_m`$, the bases of $`\mathbb{R}^m`$
    - $`\exists c_1, \cdots, c_m\in\mathbb{R}`$ s.t. $`\displaystyle T(v) = \sum_{i=1}^m c_i T(v_i)`$
      - cf.) $`T(v_1),\cdots T(v_m)`$ are the information needed to get $`T(v)`$.
      - $`c_1, \cdots, c_m\in\mathbb{R}`$ are the coordinates
- Target)
  - Find $`A\in\mathbb{R}^{n\times m}`$ s.t. $`u = Av`$
- Steps)
  - Choose the bases of the input 
    - i.e.) $`v_1, \cdots, v_m`$, the bases of $`\mathbb{R}^m`$
  - Choose the bases of the output 
    - $`w_1, \cdots, w_n\in\mathbb{R}`$
  - Then the $`i`$-th column of $`A`$ can be written as
    - $`\begin{bmatrix} a_{1i}\\a_{2i}\\\vdots\\ a_{ni}\\ \end{bmatrix}`$ where $`\displaystyle T(v_i) = \sum_{j=1}^n a_{ji} w_j`$

<br>

#### e.g.) Projection
- Suppose we want to project $`u`$ on $`v`$ where $`u,v \in\mathbb{R}^n`$.
- We can calculate $`a=\text{Proj}_v(u)\in\mathbb{R}^n`$.
- Our goal is to find $`A\in\mathbb{R}^{n\times n}`$ s.t. $`a = Au`$
- Then, instead of the initial bases $`\begin{bmatrix} 1\\0 \end{bmatrix}`$ and $`\begin{bmatrix} 0\\1 \end{bmatrix}`$, we may choose new basis $`v, v'`$ where $`v\perp v'`$.
- On the $`vv'`$ plane, we know that
  - $`\exists c_1, c_2 \in\mathbb{R}`$ s.t. $`\begin{cases} u=c_1v+c_2v' \\ a = c_1v & (\because a \text{ is a projection on } v) \end{cases}`$
  - Here, $`(c_1, 0), (c_1, c_2)`$ are the coordinates of $`a, u`$ on $`vv'`$ plane.
- Thus,   
  $`\begin{aligned}
    \underbrace{\begin{bmatrix} v & v' \end{bmatrix}\begin{bmatrix} c_1 \\ 0 \end{bmatrix}}_{a} = A \underbrace{\begin{bmatrix} v & v' \end{bmatrix}\begin{bmatrix} c_1 \\ c_2 \end{bmatrix}}_{u} 
    & \Rightarrow \begin{bmatrix} c_1 \\ c_2 \end{bmatrix} = A \begin{bmatrix} c_1 \\ 0 \end{bmatrix} & (\because v \perp v' \Rightarrow \begin{bmatrix} v & v' \end{bmatrix} \text{ is invertible.}) \\
    & \Rightarrow A = \begin{bmatrix} 1&0\\0&0 \end{bmatrix}
  \end{aligned}`$
  - cf.) This is the eigenvector basis.
    - In this case, $`A`$ is the eigenvalue matrix diagonal $`\Lambda`$

<br>

#### e.g.) Derivative
- We can think of $`T :\mathbb{R}^{n}\rightarrow\mathbb{R}^{n-1}`$
- e.g.)
  - Consider $`f(x) = c_1 + c_2x+c_3x^2`$.
  - Then $`\frac{d}{dx}f(x) = c_2 + 2c_3`$.
  - We can think of this as   
    $`A\begin{bmatrix} c_1\\c_2\\c_3 \end{bmatrix} = \begin{bmatrix} c_2\\2c_3 \end{bmatrix}`$.
  - Thus,   
    $`A=\begin{bmatrix} 0&1&0 \\ 0&0&2 \end{bmatrix}`$


<br>

[Back to Linear Algebra main](../../main.md)