[Back to Linear Algebra main](../../main.md)

# 33. Left and Right Inverses; Pseudoinverse
### Concept) Left Inverse
- Condition
  - Full column rank
    - i.e.) $`\text{rank}(A) = n, \; A\in\mathbb{R}^{m\times n}`$
      - Columns are independent!
      - $`\text{Null}(A) = \{0\}`$
      - $`Ax = b`$ has 0 or 1 solution.
- Formula
  - $`A_{\text{left}}^{-1} = \underbrace{(A^\top A)^{-1}}_{\mathbb{R}^{n\times n}} \underbrace{A^\top}_{\mathbb{R}^{n\times m}} \in\mathbb{R}^{n\times m}`$
    - Pf.)
      - $`A_{\text{left}}^{-1} A = ((A^\top A)^{-1} A^\top)A = (A^\top A)^{-1}(A^\top A) = I_n \in\mathbb{R}^{n\times n}`$

<br>

### Concept) Right Inverse
- Condition
  - Full row rank
    - i.e.) $`\text{rank}(A) = m \lt n, \; A\in\mathbb{R}^{m\times n}`$
      - Rows are independent!
      - $`\text{Null}(A^\top) = \{0\}`$
- Formula
  - $`A_{\text{right}}^{-1} = \underbrace{A^\top}_{\mathbb{R}^{n\times m}} \underbrace{(A A^\top)^{-1}}_{\mathbb{R}^{m\times m}} \in\mathbb{R}^{n\times m}`$
    - Pf.)
      - $`A A_{\text{right}}^{-1} = A(A^\top (A A^\top)^{-1}) = (A^\top A)(A^\top A)^{-1} = I_m \in\mathbb{R}^{m\times m}`$

<br>

### Concept) Pseudo-Inverse
- Situation)
  - Not full rank on both column and row.
- Idea)
  - Recall that $`\text{rank}(A) = \text{rank}(\text{column}(A)) = \text{rank}(\text{row}(A))`$
  - And from the system of linear equations $`Ax=b`$,
    - $`x\in\text{row}(A)`$
    - $`Ax\in\text{column}(A)`$
  - Thus, we may assume that $`x`$ and $`Ax`$ has the one-to-one relationship.
    - i.e.) $`\forall x,y\in\text{row}(A), x\ne y \Rightarrow Ax \ne Ay`$
      - Pf.)
        - Suppose $`x=y`$.
        - Then $`Ax = Ay \Rightarrow A(x-y) = A0 = 0`$.
        - Thus, $`x, y, 0 \in\text{row}(A)`$
  - Let's call this one-to-one relationship, the pseudo-inverse.
- Notation)
  - $`A^{+}`$ s.t. $`x = A^+ (Ax)`$
- How to get pseudo-inverse)
  - Let $`A\in\mathbb{R}^{m\times n}`$.
  - Start from the [SVD](2900.md#concept-singular-value-decomposition-svd) : $`A = U\Sigma V^\top`$ 
    - where $`\Sigma = \begin{bmatrix} \sigma_1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ 0 & \sigma_2 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \sigma_r & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \end{bmatrix} \in\mathbb{R}^{m\times n}`$
  - Then, the pseudo-inverse of $`\Sigma`$ would be   
    $`\Sigma^+ = \begin{bmatrix} \frac{1}{\sigma_1} & 0 & \cdots & 0 & 0 & \cdots & 0 \\ 0 & \frac{1}{\sigma_2} & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \frac{1}{\sigma_r} & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \end{bmatrix} \in\mathbb{R}^{n\times m}`$
  - We may have   
    $`\Sigma\Sigma^+ = \underbrace{\begin{bmatrix} 1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \end{bmatrix}}_{\in\mathbb{R}^{m\times m}}, \quad \Sigma^+\Sigma = \underbrace{\begin{bmatrix} 1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 & 0 & \cdots & 0 \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 0 & 0 & \cdots & 0 \\ \end{bmatrix}}_{\in\mathbb{R}^{n\times n}}`$
  - Now, going back to $`A`$, we have $`A^+ = V\Sigma^+ U^\top`$


<br>

[Back to Linear Algebra main](../../main.md)