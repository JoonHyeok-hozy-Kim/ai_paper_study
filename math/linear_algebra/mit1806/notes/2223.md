[Back to Linear Algebra main](../../main.md)

# 22. Diagonalization and Powers of A / 23. Differential Equations and exp(At)

### Concept) Diagonalization
- Settings)
  - $`A\in\mathbb{R}^{n\times n}`$
    - where
      - $`A`$ has $`n`$ linearly independent eigenvectors : $`x_1, \cdots, x_n`$
  - $`S = \begin{bmatrix} x_1 & x_2 &\cdots & x_n \end{bmatrix}`$
    - where $`x_i \in\mathbb{R}^n`$ : the eigenvector of $`A`$ w.r.t. $`\lambda_i`$
  - $`\Lambda = \begin{bmatrix}
        \lambda_1 & 0 & \cdots & 0 \\
        0 & \lambda_2 & \cdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \cdots & \lambda_n
    \end{bmatrix}`$ : a diagonal matrix with diagonal values of eigenvectors of $`A`$.  
- Thm.)   
  - $`S^{-1} A S = \Lambda`$
    - Pf.)   
      - Consider that   
        $`\begin{aligned}
        AS &= A\begin{bmatrix} x_1 & x_2 &\cdots & x_n \end{bmatrix} \\
        &= \begin{bmatrix} Ax_1 & Ax_2 &\cdots & Ax_n \end{bmatrix} \\
        &= \begin{bmatrix} \lambda_1x_1 & \lambda_2x_2 &\cdots & \lambda_n x_n \end{bmatrix} & (\because Ax_i = \lambda_i x_i) \\
        &= \begin{bmatrix} x_1 & x_2 &\cdots & x_n \end{bmatrix} \begin{bmatrix}
            \lambda_1 & 0 & \cdots & 0 \\
            0 & \lambda_2 & \cdots & 0 \\
            \vdots & \vdots & \ddots & \vdots \\
            0 & 0 & \cdots & \lambda_n
        \end{bmatrix} \\
        &= S\Lambda
        \end{aligned}`$
      - Thus, $`S^{-1} A S = \Lambda \quad (\because A \text{ has } n \text{ indep. eigenvecgtors} \Leftrightarrow S \text{ is invertible.})`$
- Prop.)
  - If $`A`$ does not have $`n`$ independent eigenvectors, $`S`$ is not invertible.
    - Why?)
      - $`\exists x_i, x_j`$ s.t. $`x_i = x_j`$
  - $`A^k = S\Lambda^k S^{-1} = \begin{bmatrix} x_1 & x_2 &\cdots & x_n \end{bmatrix} \begin{bmatrix}
            \lambda_1^k & 0 & \cdots & 0 \\
            0 & \lambda_2^k & \cdots & 0 \\
            \vdots & \vdots & \ddots & \vdots \\
            0 & 0 & \cdots & \lambda_n^k
        \end{bmatrix} \begin{bmatrix} x_1 & x_2 &\cdots & x_n \end{bmatrix} `$
  - $`\displaystyle \lim_{k\rightarrow\infty} A = 0 \Leftrightarrow \vert \lambda_i \vert \lt 1`$
  - If all eigenvalues are different, $`A`$ has $`n`$ independent eigenvectors.
    - Thus, $`A`$ is diagonalizable.
      - cf.) If $`A`$ has a repeated eigenvalue, $`A`$ may or may not have $`n`$ independent eigenvalues.

<br>

### Concept) System of Differential Equations
- Target)
  - $`u_{k+1} = Au_k`$
    - i.e.) $`u_k = A^k u_0`$
- Cases)
  - $`\displaystyle u_0 = \sum_{i=1}^n c_i x_i = \begin{bmatrix}
            \lambda_1 & 0 & \cdots & 0 \\
            0 & \lambda_2 & \cdots & 0 \\
            \vdots & \vdots & \ddots & \vdots \\
            0 & 0 & \cdots & \lambda_n
        \end{bmatrix} \begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_n \end{bmatrix} = Sc`$ 
    - where 
      - $`c_i\in\mathbb{R}`$ 
      - $`x_i`$ is the eigenvector of $`A`$ w.r.t. $`\lambda_i`$
    - Then,   
      $`\begin{aligned}
        Au_0 &= A\sum_{i=1}^n c_i x_i = \sum_{i=1}^n c_i Ax_i \\
        &= \sum_{i=1}^n c_i \lambda_i x_i \\
        Au_1 &= Au_0 = A \sum_{i=1}^n c_i \lambda_i x_i = \sum_{i=1}^n c_i \lambda_i Ax_i =  \\
        &= \sum_{i=1}^n c_i \lambda_i^2 x_i \\
        \vdots \\
        Au_{k} &= \sum_{i=1}^n c_i \lambda_i^k x_i = A^ku_0 \\
      \end{aligned}`$
      - Prop.)
        - $`A^k u_0 = \Lambda^k S c`$
  - Fibonacci : $`F_{n+2} = F_{n+1} + F_{n}`$ 
    - Trick : Use the following system   
      $`\begin{cases} F_{n+2} = F_{n+1} + F_{n} \\ F_{k+1} = F_{k+1} \end{cases} `$
    - Denote with the matrix : $`u_n = \begin{bmatrix} F_{n+1} \\ F_{n} \end{bmatrix} `$
    - Then, we have $`u_{n+1} = \begin{bmatrix} F_{n+1} + F_{n} \\ F_{n+1} \end{bmatrix} = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix} u_n`$
    - Thus, $`u_n = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}^n u_0 = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}^n \begin{bmatrix} 1 \\ 0 \end{bmatrix}`$.
    - Furthermore,   
      $`\begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}^n = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} \frac{1}{2}(1+\sqrt{5}) & 0 \\ 0 & \frac{1}{2}(1-\sqrt{5}) \end{bmatrix}^n \begin{bmatrix} x_1 & x_2 \end{bmatrix}`$
    - Hence,   
      $`u_n = \begin{bmatrix} \frac{1}{2}(1+\sqrt{5}) & \frac{1}{2}(1-\sqrt{5}) \\ 1 & 1 \end{bmatrix} \begin{bmatrix} \frac{1}{2}(1+\sqrt{5}) & 0 \\ 0 & \frac{1}{2}(1-\sqrt{5}) \end{bmatrix}^n \begin{bmatrix} \frac{1}{2}(1+\sqrt{5}) & \frac{1}{2}(1-\sqrt{5}) \\ 1 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix}`$

<br>

### Concept) Differential Equations : System of First Order Derivative
- Target)
  - $`\displaystyle \frac{du}{dt} = Au`$
- Prop.)
  - Steady State Condition : $`\lambda_i = 0`$  
  - Convergence Condition : $``$

<br>

### Concept) Matrix Exponential
- Taylor Series)
  - $`\displaystyle e^{At} = I + At + \frac{(At)^2}{2} + \frac{(At)^3}{6} + \cdots  + \frac{(At)^n}{n!} + \cdots = \sum_{n=1}^{\infty} \frac{(At)^n}{n!}`$
    - Derived from $`\displaystyle e^x = \sum_{n=1}^{\infty} \frac{x^n}{n!}`$
    - If $`A`$ is [diagonalizable](#concept-diagonalization),   
      $`\begin{aligned}
        e^{At} &= SS^{-1} + S\Lambda S^{-1}t + \frac{S\Lambda^2 S^{-1}}{2}t^2 +  + \frac{S\Lambda^3 S^{-1}}{6} t^3+ \cdots  + \frac{S\Lambda^n S^{-1}}{n!}t^n + \cdots  \\
        &= Se^{\Lambda t}S^{-1}, \quad \text{ where } e^{\Lambda t} = \begin{bmatrix} e^{\lambda_1 t} & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & e^{\lambda_n t} \end{bmatrix}
      \end{aligned}`$
- Geometric Series)
  - $`\displaystyle (I-At)^{-1} = I + (At) + (At)^2 + (At)^3 + \cdots = \sum_{n=1}^{\infty} (At)^n`$
    - Derived from $`\displaystyle \frac{1}{1-x} = \sum_{n=1}^{\infty} x^n`$
    - Prop.)
      - $`\vert \lambda (At)\vert \lt 1 \Rightarrow (I-At)^{-1}`$ converges
- Differential)
  - $`y'' + b y' + Ky = 0`$
    - Let $`u = \begin{bmatrix} y' \\ y \end{bmatrix}`$
      - similar to [the Fibonacci example above](#concept-system-of-differential-equations).
    - Then   
      $`u' = \begin{bmatrix} y'' \\ y' \end{bmatrix} = \begin{bmatrix} -b & -K \\ 1 & 0 \end{bmatrix}\begin{bmatrix} y' \\ y \end{bmatrix}`$



<br>

[Back to Linear Algebra main](../../main.md)